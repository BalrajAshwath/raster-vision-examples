{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpaceNet Rio Chip Classification Data Prep\n",
    "\n",
    "This notebook prepares data for training a chip classification model on the Rio SpaceNet dataset.\n",
    "\n",
    "The only thing you'll have to set to run this notebook is to put an S3 URI that you have write access to here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label_prefix = \"s3://raster-vision-spacenet/AOI_1_Rio/buildingLabels\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps we'll take to make the data are as follows:\n",
    "\n",
    "- Download the building labels and AOI from the SpaceNet AWS public dataset bucket\n",
    "- Use the AOI and the image bounds to determine which images can be used for training and validation\n",
    "- Split the building labels by image, save off a label GeoJSON file per image, and upload to S3\n",
    "- Split the labeled images into a training and validation set, using the percentage of the AOI each covers, aiming at an 80%/20% split.\n",
    "\n",
    "This process will save off of the split labels to S3, and save off a `train_scenes.csv` and `val_scenes.csv` that is used by the experiment at `spacenet.chip_classification`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import rastervision as rv\n",
    "import boto3\n",
    "import botocore\n",
    "import rasterio\n",
    "from shapely.geometry import (Polygon, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the label and AOI data from AWS's public dataset of Space Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = '/opt/data/spacenet/rio/labels/Rio_Buildings_Public_AOI_v2.geojson'\n",
    "aoi_path = '/opt/data/spacenet/rio/labels/Rio_OUTLINE_Public_AOI.geojson'\n",
    "if not os.path.exists(label_path):\n",
    "    !aws s3 cp s3://spacenet-dataset/AOI_1_Rio/srcData/buildingLabels/Rio_Buildings_Public_AOI_v2.geojson $label_path\n",
    "    !aws s3 cp s3://spacenet-dataset/AOI_1_Rio/srcData/buildingLabels/Rio_OUTLINE_Public_AOI.geojson $aoi_path\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the AOI to determine what images are inside the training set\n",
    "\n",
    "Here we compare the AOI to the image extends to deteremine which images we can use for training and validation. We're using `rasterio`'s ability to read the metadata from raster data on S3 without downloading the whole image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = None\n",
    "with open(aoi_path) as f:\n",
    "    aoi = shape(json.loads(f.read())['features'][0]['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'spacenet-dataset'\n",
    "key = 'AOI_5_Khartoum/AOI_5_Khartoum_Train.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'AOI_1_Rio/srcData/mosaic_3band/'\n",
    "image_files = list(map(lambda x: 's3://{}/{}'.format(bucket, x['Key']),\n",
    "                       s3.list_objects(Bucket=bucket, Prefix=prefix)['Contents']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounds_to_shape(bounds):\n",
    "    return Polygon([[bounds.left, bounds.bottom],\n",
    "                    [bounds.left, bounds.top],\n",
    "                    [bounds.right, bounds.top],\n",
    "                    [bounds.right, bounds.bottom],\n",
    "                    [bounds.left, bounds.bottom]])\n",
    "image_to_extents = {}\n",
    "for img in image_files:\n",
    "    with rasterio.open(img, 'r') as ds:\n",
    "        image_to_extents[img] = bounds_to_shape(ds.bounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersecting_images = []\n",
    "for img in image_to_extents:\n",
    "    if image_to_extents[img].intersects(aoi):\n",
    "        intersecting_images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersecting_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match labels to images\n",
    "\n",
    "Find the labels that intersect with the image's bounding box, which will be saved off into a labels geojson that matches the image name. Upload them to the S3 URI at `target_label_prefix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_js = None\n",
    "with open(label_path) as f:\n",
    "    label_js = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a class_id and class_name to the properties of each feature\n",
    "for feature in label_js['features']:\n",
    "    feature['properties']['class_id'] = 1\n",
    "    feature['properties']['class_name'] = 'building'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_to_features = {}\n",
    "for img in  intersecting_images:\n",
    "    image_to_features[img] = []\n",
    "    bbox = image_to_extents[img]\n",
    "    for feature in label_js['features']:\n",
    "        if shape(feature['geometry']).intersects(bbox):\n",
    "            image_to_features[img].append(feature)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_labels_dir = '/opt/data/spacenet/rio/processed_labels/'\n",
    "if not os.path.isdir(processed_labels_dir):\n",
    "    os.makedirs(processed_labels_dir)\n",
    "for img in image_to_features:\n",
    "    fc = {}\n",
    "    fc['type'] = 'FeatureCollection'\n",
    "    fc['crs'] = label_js['crs']\n",
    "    fc['features'] = image_to_features[img]\n",
    "    basename = os.path.splitext(os.path.basename(img))[0]\n",
    "    with open(os.path.join(processed_labels_dir,'{}.geojson'.format(basename)), 'w') as f:\n",
    "        f.write(json.dumps(fc, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $processed_labels_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive $processed_labels_dir $target_label_prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train and validation\n",
    "\n",
    "Split up training and validation data. There's an odd shaped AOI and not that many images, so we'll split the train and validation roughly based on how much area each scene covers of the AOI. \n",
    "\n",
    "Create a CSV that our experiments will use to load up the training and validation data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and validation\n",
    "ratio = 0.8\n",
    "aoi_area = aoi.area\n",
    "images_to_area = {}\n",
    "for img in intersecting_images:\n",
    "    area = image_to_extents[img].intersection(aoi).area\n",
    "    images_to_area[img] = area / aoi_area\n",
    "\n",
    "train_imgs = []\n",
    "val_imgs = []\n",
    "train_area_covered = 0\n",
    "for img in sorted(intersecting_images, reverse=True, key=lambda img: images_to_area[img]):\n",
    "    if train_area_covered < ratio:\n",
    "        train_imgs.append(img)\n",
    "        train_area_covered += images_to_area[img]\n",
    "    else:\n",
    "        val_imgs.append(img)\n",
    "print(\"{} training images with {}% area.\".format(len(train_imgs), train_area_covered))\n",
    "print(\"{} validation images with {} area.\".format(len(val_imgs), 1 - train_area_covered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_rows = []\n",
    "for img in train_imgs:\n",
    "    basename = os.path.splitext(os.path.basename(img))[0]\n",
    "    labels_path = os.path.join(target_label_prefix,'{}.geojson'.format(basename))\n",
    "    csv_rows.append('\"{}\",\"{}\"'.format(img, labels_path))\n",
    "with open('/opt/data/spacenet/rio/training_scenes.csv', 'w') as f:\n",
    "    f.write('\\n'.join(csv_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_rows = []\n",
    "for img in val_imgs:\n",
    "    basename = os.path.splitext(os.path.basename(img))[0]\n",
    "    labels_path = os.path.join(target_label_prefix,'{}.geojson'.format(basename))\n",
    "    csv_rows.append('\"{}\",\"{}\"'.format(img, labels_path))\n",
    "with open('/opt/data/spacenet/rio/val_scenes.csv', 'w') as f:\n",
    "    f.write('\\n'.join(csv_rows))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
